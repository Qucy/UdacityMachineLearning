{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理\n",
    "- 原始数据集直接从Kaggle上下载，解压后train目录下一共有25000张图片，test目录下一共有12500张图片\n",
    "- 我们需要通过Keras ImageDataGenerator的flow_from_directory方法来加载我们的图片，所以我们需要将训练集和测试集的图片放到子文件夹中\n",
    "- 测试集很简单，建一个子目录，将文件全部移动过去就行\n",
    "- 训练集需要建立两个子目录，将狗和猫的图片分别移动到两个子目录中去\n",
    "- 训练集中的图片名称格式为{种类}.序号.jpg，比如 cat.1.jpg 或 dog.1.jpg。我们可以利用命名规则来移动训练集的图片\n",
    "\n",
    "当前的图片目录结构如下\n",
    "```\n",
    "data\n",
    " ├── test   [12500 images]\n",
    " └── train  [25000 images]\n",
    "```\n",
    "预处理后图片目录结构如下\n",
    "```\n",
    "data\n",
    " ├── test\n",
    " │   └── none [12500 images]\n",
    " └── train\n",
    "     ├── cat  [12500 images]\n",
    "     └── dog  [12500 images]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat images:  12500\n",
      "dog images:  12500\n",
      "test images:  12500\n"
     ]
    }
   ],
   "source": [
    "# 数据处理代码\n",
    "import os\n",
    "from shutil import move\n",
    "\n",
    "train_src = 'data/train/'\n",
    "test_src = 'data/test/'\n",
    "dog_dest = 'data/train/dog/'\n",
    "cat_dest = 'data/train/cat/'\n",
    "test_dest = 'data/test/none/'\n",
    "\n",
    "#创建子目录\n",
    "os.makedirs(dog_dest, exist_ok=True)\n",
    "os.makedirs(cat_dest, exist_ok=True)\n",
    "os.makedirs(test_dest, exist_ok=True)\n",
    "\n",
    "#移动测试图片至子文件夹中\n",
    "for root, dirs, files in os.walk(test_src):\n",
    "    if(root == test_src):\n",
    "        for name in files:\n",
    "            if(name.find('jpg')>-1):\n",
    "                move(test_src + name, test_dest + name)\n",
    "\n",
    "#移动训练集图片至对应的子文件夹中\n",
    "for root, dirs, files in os.walk(train_src):\n",
    "    if(root == train_src):\n",
    "        for name in files:\n",
    "            if(name.find('jpg')>-1 and name.find('cat')>-1):\n",
    "                move(train_src + name, cat_dest + name)\n",
    "            elif(name.find('jpg')>-1 and name.find('dog')>-1):\n",
    "                move(train_src + name, dog_dest + name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "print(\"cat images: \", \n",
    "      len([name for name in os.listdir(cat_dest) if os.path.isfile(os.path.join(cat_dest, name))]))\n",
    "print(\"dog images: \", \n",
    "      len([name for name in os.listdir(dog_dest) if os.path.isfile(os.path.join(dog_dest, name))]))\n",
    "print(\"test images: \", \n",
    "      len([name for name in os.listdir(test_dest) if os.path.isfile(os.path.join(test_dest, name))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出深度特征\n",
    "- 根据当前训练以及测试集导出VGG16,VGG19,ResNet50,Xception以及InceptionV3的深度特征\n",
    "- VGG16,VGG19,ResNet50要求的图片的大小为（224， 224），Xception，Inception要求的图片大小为（299，299）\n",
    "- 先对所有数据进行一个预处理的操作，把数据缩放到-1到1之间\n",
    "- 其次我们加入一个平局池化操作，一方面是缩小我们导出的深度特征文件的大小，另一方是防止过拟合\n",
    "- 最后使用Keras的ImageGenerator导出深度特征的数组，存放在本地磁盘上供接下来的模型训练使用\n",
    "- 每个模型导出深度特征的耗时，如下\n",
    "- VGG16 耗时约3分25秒\n",
    "- VGG19 耗时约3分52秒\n",
    "- ResNet50 耗时约3分30秒，\n",
    "- InceptionV3 耗时约4分34秒\n",
    "- Xception 耗时约6分钟56秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tracy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "train_data_path = 'data/train/'\n",
    "test_data_path = 'data/test/'\n",
    "\n",
    "def save_bottleneck_features(MODEL, image_size, module_name, preprocess):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = Lambda(preprocess)(input_tensor)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_data_path, image_size, shuffle=False)\n",
    "    test_generator = gen.flow_from_directory(test_data_path, image_size, shuffle=False, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator)\n",
    "    test = model.predict_generator(test_generator)\n",
    "    \n",
    "    with h5py.File(\"bottleneck_features/{}_bottleneck_features.h5\".format(module_name)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"{} extract features total consumed: {} seconds\".format(module_name, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG16 extrac features total consumed: 205.36566758155823 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(VGG16, (224, 224), 'VGG16', vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG19 extrac features total consumed: 232.02474784851074 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(VGG19, (224, 224), 'VGG19', vgg19.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "ResNet50 extrac features total consumed: 210.49121832847595 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(ResNet50, (224, 224), 'ResNet50', resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "InceptionV3 extrac features total consumed: 274.9980471134186 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(InceptionV3, (299, 299), 'InceptionV3', inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Xception extrac features total consumed: 416.50056076049805 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(Xception, (299, 299), 'Xception', xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "- 这里一共定义了3个方法，retrieve_features用于读取本地磁盘的深度特征文件并从文件中提取出X_train,X_test,y_train3个数组\n",
    "- train_model用于构建并训练自己的模型，我们的模型包含2层，BatchNormalization层是为了防止过拟合，Dense层为了做分类。\n",
    "- generate_submission_csv用于生成提交至Kaggle的文件\n",
    "- 因为Kaggle官方采用的时LogLoss作为评估标准，所以我们这里限制了预测概率的最大和最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import *\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.optimizers import *\n",
    "import time\n",
    "\n",
    "def retrieve_features(files):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    \n",
    "    for filename in files:\n",
    "        with h5py.File(filename, 'r') as h:\n",
    "            X_train.append(np.array(h['train']))\n",
    "            X_test.append(np.array(h['test']))\n",
    "            y_train = np.array(h['label'])\n",
    "        \n",
    "    X_train = np.concatenate(X_train, axis=1)\n",
    "    X_test = np.concatenate(X_test, axis=1)\n",
    "    \n",
    "    return X_train, X_test, y_train\n",
    "\n",
    "    \n",
    "\n",
    "def train_model(X_train, y_train, epochs, optimizer='adam'):\n",
    "    # construct model\n",
    "    input_tensor = Input(X_train.shape[1:])\n",
    "    x = BatchNormalization()(input_tensor)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    # compile model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # train model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, batch_size=200, epochs=epochs, validation_split=0.2, verbose=1)\n",
    "    end_time = time.time()\n",
    "    print(\"Trainning model total consumed:{} seconds\".format(end_time - start_time))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_submission_csv(X_test, model):\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test, verbose=1)\n",
    "    end_time = time.time()\n",
    "    print(\"Predicting model total consumed:{} seconds\".format(end_time - start_time))\n",
    "    y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "    df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    test_generator = gen.flow_from_directory('data/test/', (224, 224), shuffle=False, batch_size=32, class_mode=None)\n",
    "\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        index = int(fname[fname.rfind('\\\\')+1:fname.rfind('.')])\n",
    "        df.at[index-1, 'label'] = y_pred[i]\n",
    "\n",
    "    df.to_csv('data/pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迁移学习-VGG16\n",
    "- 训练了10代，一共耗时8.65秒，训练集的最高准确率可以到达0.9828，验证集的最高准确率可以到达0.9658\n",
    "- 预测一共耗时1.65秒，最后将生成的文件上传至Kaggle得分为0.08130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.3232 - acc: 0.8546 - val_loss: 0.2340 - val_acc: 0.9004\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 34us/step - loss: 0.1173 - acc: 0.9602 - val_loss: 0.1616 - val_acc: 0.9306\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0884 - acc: 0.9695 - val_loss: 0.1262 - val_acc: 0.9472\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0759 - acc: 0.9744 - val_loss: 0.1151 - val_acc: 0.9518\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0669 - acc: 0.9771 - val_loss: 0.1084 - val_acc: 0.9552\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0606 - acc: 0.9786 - val_loss: 0.0983 - val_acc: 0.9594\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0561 - acc: 0.9809 - val_loss: 0.1023 - val_acc: 0.9574\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.0530 - acc: 0.9817 - val_loss: 0.0869 - val_acc: 0.9642\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.0510 - acc: 0.9819 - val_loss: 0.0812 - val_acc: 0.9658\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.0479 - acc: 0.9828 - val_loss: 0.0838 - val_acc: 0.9646\n",
      "Trainning model total consumed:8.657156229019165 seconds\n",
      "12500/12500 [==============================] - 2s 131us/step\n",
      "Predicting model total consumed:1.6564559936523438 seconds\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bottleneck_files = [\"bottleneck_features/VGG16_bottleneck_features.h5\"]\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "model = train_model(X_train, y_train, 10)\n",
    "\n",
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  迁移学习-VGG19\n",
    "- 训练了10代，一共耗时8.53秒，训练集的最高准确率可以到达0.9848，验证集的最高准确率可以到达0.9728\n",
    "- 预测一共耗时1.63秒，最后将生成的文件上传至Kaggle得分为0.07487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.2963 - acc: 0.8725 - val_loss: 0.1978 - val_acc: 0.9190\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1010 - acc: 0.9678 - val_loss: 0.1290 - val_acc: 0.9496\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.0768 - acc: 0.9746 - val_loss: 0.1133 - val_acc: 0.9554\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0659 - acc: 0.9778 - val_loss: 0.0990 - val_acc: 0.9610\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0578 - acc: 0.9804 - val_loss: 0.0898 - val_acc: 0.9636\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.0550 - acc: 0.9814 - val_loss: 0.0833 - val_acc: 0.9660\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0516 - acc: 0.9829 - val_loss: 0.0872 - val_acc: 0.9654\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0486 - acc: 0.9836 - val_loss: 0.0757 - val_acc: 0.9698\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0465 - acc: 0.9842 - val_loss: 0.0728 - val_acc: 0.9720\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.0437 - acc: 0.9848 - val_loss: 0.0702 - val_acc: 0.9728\n",
      "Trainning model total consumed:8.53214144706726 seconds\n",
      "12500/12500 [==============================] - 2s 130us/step\n",
      "Predicting model total consumed:1.6252193450927734 seconds\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bottleneck_files = [\"bottleneck_features/VGG19_bottleneck_features.h5\"]\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "model = train_model(X_train, y_train, 10)\n",
    "\n",
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  迁移学习-ResNet50\n",
    "- 训练了5代，训练一共耗时5.92秒，训练集的最高准确率可以到达0.9921，验证集的最高准确率可以到达0.9830\n",
    "- 预测一共耗时0.5秒，最后将生成的文件上传至Kaggle得分为0.06036\n",
    "- 这里只训练5代的原因是，多次训练后发现5代之后容易出现过拟合的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.1150 - acc: 0.9528 - val_loss: 0.0588 - val_acc: 0.9784\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.0395 - acc: 0.9867 - val_loss: 0.0555 - val_acc: 0.9802\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.0311 - acc: 0.9899 - val_loss: 0.0596 - val_acc: 0.9794\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.0271 - acc: 0.9910 - val_loss: 0.0486 - val_acc: 0.9830\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.0238 - acc: 0.9921 - val_loss: 0.0493 - val_acc: 0.9826\n",
      "Trainning model total consumed:5.922510862350464 seconds\n",
      "12500/12500 [==============================] - 1s 43us/step\n",
      "Predicting model total consumed:0.5312831401824951 seconds\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bottleneck_files = [\"bottleneck_features/ResNet50_bottleneck_features.h5\"]\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "model = train_model(X_train, y_train, 5)\n",
    "\n",
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  迁移学习-InceptionV3\n",
    "- 训练了3代，训练一共耗时3.84秒，训练集的最高准确率可以到达0.9943，验证集的最高准确率可以到达0.9912\n",
    "- 预测一共耗时0.7秒，最后将生成的文件上传至Kaggle得分为0.04588\n",
    "- 这里只训练了3代，因为仅仅3代之后就非常容易出现过拟合的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 2s 81us/step - loss: 0.0855 - acc: 0.9643 - val_loss: 0.0291 - val_acc: 0.9902\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.0226 - acc: 0.9927 - val_loss: 0.0298 - val_acc: 0.9898\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0274 - val_acc: 0.9912\n",
      "Trainning model total consumed:3.8441414833068848 seconds\n",
      "12500/12500 [==============================] - 1s 56us/step\n",
      "Predicting model total consumed:0.7031993865966797 seconds\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bottleneck_files = [\"bottleneck_features/InceptionV3_bottleneck_features.h5\"]\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "model = train_model(X_train, y_train, 3)\n",
    "\n",
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  迁移学习-Xception\n",
    "- 训练了5代，训练一共耗时8.15秒，训练集的最高准确率可以到达0.9963，验证集的最高准确率可以到达0.9946\n",
    "- 预测一共耗时1.3秒，最后将生成的文件上传至Kaggle得分为0.04630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.0743 - acc: 0.9710 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.0210 - acc: 0.9933 - val_loss: 0.0204 - val_acc: 0.9946\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0251 - val_acc: 0.9934\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0246 - val_acc: 0.9932\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0272 - val_acc: 0.9928\n",
      "Trainning model total consumed:8.157132863998413 seconds\n",
      "12500/12500 [==============================] - 1s 104us/step\n",
      "Predicting model total consumed:1.3126063346862793 seconds\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bottleneck_files = [\"bottleneck_features/Xception_bottleneck_features.h5\"]\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "model = train_model(X_train, y_train, 5)\n",
    "\n",
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  迁移学习-集成所有模型的属性\n",
    "- 训练了15代，训练一共耗时23.59秒，训练集的最高准确率可以到达0.9978，验证集的最高准确率可以到达0.9944\n",
    "- 预测一共耗时1.56秒，最后将生成的文件上传至Kaggle得分为0.03762\n",
    "- 这里我们自定义了一个learning rate更小的optimzer，防止模型学习过快，无法正常收敛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/15\n",
      "20000/20000 [==============================] - 4s 176us/step - loss: 0.2147 - acc: 0.9085 - val_loss: 0.0357 - val_acc: 0.9926\n",
      "Epoch 2/15\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0399 - acc: 0.9904 - val_loss: 0.0268 - val_acc: 0.9932\n",
      "Epoch 3/15\n",
      "20000/20000 [==============================] - 2s 75us/step - loss: 0.0274 - acc: 0.9927 - val_loss: 0.0232 - val_acc: 0.9932\n",
      "Epoch 4/15\n",
      "20000/20000 [==============================] - 2s 77us/step - loss: 0.0223 - acc: 0.9933 - val_loss: 0.0210 - val_acc: 0.9932\n",
      "Epoch 5/15\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0193 - acc: 0.9945 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "Epoch 6/15\n",
      "20000/20000 [==============================] - 2s 77us/step - loss: 0.0171 - acc: 0.9946 - val_loss: 0.0174 - val_acc: 0.9946\n",
      "Epoch 7/15\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0160 - acc: 0.9955 - val_loss: 0.0199 - val_acc: 0.9932\n",
      "Epoch 8/15\n",
      "20000/20000 [==============================] - 2s 80us/step - loss: 0.0140 - acc: 0.9959 - val_loss: 0.0193 - val_acc: 0.9934\n",
      "Epoch 9/15\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0133 - acc: 0.9962 - val_loss: 0.0172 - val_acc: 0.9944\n",
      "Epoch 10/15\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 0.0174 - val_acc: 0.9944\n",
      "Epoch 11/15\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 12/15\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.0105 - acc: 0.9972 - val_loss: 0.0179 - val_acc: 0.9940\n",
      "Epoch 13/15\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0202 - val_acc: 0.9928\n",
      "Epoch 14/15\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0168 - val_acc: 0.9938\n",
      "Epoch 15/15\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0179 - val_acc: 0.9932\n",
      "Trainning model total consumed:23.59627342224121 seconds\n",
      "12500/12500 [==============================] - 2s 125us/step\n",
      "Predicting model total consumed:1.5626370906829834 seconds\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "bottleneck_files = [\"bottleneck_features/VGG16_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/VGG19_bottleneck_features.h5\", \n",
    "                    \"bottleneck_features/ResNet50_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/InceptionV3_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/Xception_bottleneck_features.h5\"]\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model = train_model(X_train, y_train, 15, optimizer)\n",
    "\n",
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logloss(true_label, predicted):\n",
    "    if true_label == 1:\n",
    "        return -math.log(predicted)\n",
    "    else:\n",
    "        return -math.log(1 - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010005003335835344\n",
      "0.0010005003335835344\n",
      "48.35428695287496\n",
      "0.916290731874155\n"
     ]
    }
   ],
   "source": [
    "# 当我们预测正确时 true label = 1 , 我们预测的值为 0.999时\n",
    "print(logloss(1, 0.999))\n",
    "# 当我们预测正确时 true label = 0 , 我们预测的值为 0.001时\n",
    "print(logloss(0, 0.001))\n",
    "\n",
    "# 当我们预测错误时 true label = 1 , 我们预测的值为 0.4时\n",
    "print(logloss(1, 0.000000000000000000001))\n",
    "# 当我们预测错误时 true label = 0 , 我们预测的值为 0.6时\n",
    "print(logloss(0, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
