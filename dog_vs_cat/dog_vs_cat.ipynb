{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迁移学习\n",
    "\n",
    "- 通过运行上方的代码，大概知道了各个模型的一个表现情况，因为VGG19的表现相对较差而，模型较大，训练起来会偏慢，所以放弃这个模型；\n",
    "- 下面需要对剩下的三个模型进行迁移学习，首先我们获取三个模型的base部分，即不包含最后全连接层的模型；\n",
    "- 然后我们用这些基础模型根据data generator来做预测得到3个模型的bottleneck_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline \n",
    "\n",
    "# save features\n",
    "def save_bottle_neck_features(filename, train_features, test_features, train_labels):\n",
    "    with h5py.File(\"bottleneck_features/{}.hdf5\".format(filename), \"w\") as f:\n",
    "        dset = f.create_dataset(\"train\", data=train_features)\n",
    "        dset = f.create_dataset(\"test\", data=test_features)\n",
    "        dset = f.create_dataset(\"label\", data=train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Extrac feature finished! Total consumed: 0:57:18.320957 \n"
     ]
    }
   ],
   "source": [
    "# 定义input_tensor\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "# 获取base model\n",
    "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "# 加一层pooling，不然数据太大了！而且可以防止拟合\n",
    "model = Model(resnet_base_model.input, GlobalAveragePooling2D()(resnet_base_model.output))\n",
    "# 记录当前时间\n",
    "start_time = datetime.now()\n",
    "\n",
    "train_data_path = 'data/train/'\n",
    "test_data_path = 'data/test/'\n",
    "train_data_size = 25000\n",
    "test_data_size = 12500\n",
    "image_size = (224, 224)\n",
    "\n",
    "generator = ImageDataGenerator()\n",
    "\n",
    "train_generator = generator.flow_from_directory(train_data_path, image_size, shuffle=False, batch_size=16)\n",
    "test_generator = generator.flow_from_directory(test_data_path, image_size, shuffle=False, batch_size=16)\n",
    "\n",
    "train_bottleneck_features = model.predict_generator(train_generator, train_data_size)\n",
    "test_bottleneck_features = model.predict_generator(train_generator, test_data_size)\n",
    "\n",
    "save_bottle_neck_features(\"restnet_bottleneck_features\", train_bottleneck_features, test_bottleneck_features, \n",
    "                          train_generator.classes)\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"Extract feature finished! Total consumed: {} \".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Extract feature finished! Total consumed: 1:51:56.502403 \n"
     ]
    }
   ],
   "source": [
    "# 定义input_tensor\n",
    "input_tensor = Input(shape=(299, 299, 3))\n",
    "# 预处理数据\n",
    "input_tensor = Lambda(xception.preprocess_input)(input_tensor)\n",
    "# 获取xception base model\n",
    "xception_base_model = Xception(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "model = Model(xception_base_model.input, GlobalAveragePooling2D()(xception_base_model.output))\n",
    "# 重新定义image_size\n",
    "image_size = (299, 299)\n",
    "# 记录当前时间\n",
    "start_time = datetime.now()\n",
    "\n",
    "train_generator = generator.flow_from_directory(train_data_path, image_size, shuffle=False, batch_size=16)\n",
    "test_generator = generator.flow_from_directory(test_data_path, image_size, shuffle=False, batch_size=16)\n",
    "\n",
    "train_bottleneck_features = model.predict_generator(train_generator, train_data_size)\n",
    "test_bottleneck_features = model.predict_generator(train_generator, test_data_size)\n",
    "\n",
    "save_bottle_neck_features(\"xception_bottleneck_features\", train_bottleneck_features, test_bottleneck_features, \n",
    "                          train_generator.classes)\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"Extract feature finished! Total consumed: {} \".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract feature finished! Total consumed: 1:13:46.941855 \n"
     ]
    }
   ],
   "source": [
    "# 定义input_tensor\n",
    "input_tensor = Input(shape=(299, 299, 3))\n",
    "# 预处理数据\n",
    "input_tensor = Lambda(inception_v3.preprocess_input)(input_tensor)\n",
    "# 获取inception base model\n",
    "inception_base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "# 加一层pooling，不然数据太大了！而且可以防止拟合\n",
    "model = Model(inception_base_model.input, GlobalAveragePooling2D()(inception_base_model.output))\n",
    "# 记录当前时间\n",
    "start_time = datetime.now()\n",
    "\n",
    "train_bottleneck_features = model.predict_generator(train_generator, train_data_size)\n",
    "test_bottleneck_features = model.predict_generator(train_generator, test_data_size)\n",
    "\n",
    "save_bottle_neck_features(\"inception_bottleneck_features\", train_bottleneck_features, test_bottleneck_features, \n",
    "                          train_generator.classes)\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"Extract feature finished! Total consumed: {} \".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_and_predict(bottleneck_file_path):\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    text_x = []\n",
    "    \n",
    "    with h5py.File(bottleneck_file_path, 'r') as h:\n",
    "        train_x = np.array(h['train'])\n",
    "        train_y = np.array(h['label'])\n",
    "        text_x = np.array(h['test'])\n",
    "    \n",
    "    input_tensor = Input(train_x.shape[1:])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation='sigmod')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(train_x, train_y, batch_size=120, nb_epoch=10, validation_split=0.2)\n",
    "    # predict\n",
    "    preds = model.predict(text_x)\n",
    "    # generate kaggle submission file\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399880, 2048) (25000,) (199944, 2048)\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "text_x = []\n",
    "\n",
    "with h5py.File('bottleneck_features\\inception_bottleneck_features.hdf5', 'r') as h:\n",
    "    train_x = np.array(h['train'])\n",
    "    train_y = np.array(h['label'])\n",
    "    text_x = np.array(h['test'])\n",
    "    \n",
    "print(train_x.shape, train_y.shape, text_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8a5263c55dc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "train_x = np.concatenate(train_x, axis=1)\n",
    "text_x = np.concatenate(text_x, axis=1)\n",
    "\n",
    "input_tensor = Input(train_x.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "# compile model\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(train_x, train_y, batch_size=120, epochs=10, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
