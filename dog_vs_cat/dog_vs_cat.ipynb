{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理\n",
    "- 原始数据集直接从Kaggle上下载，解压并且经过预处理之后分别放在 train/cat，train/dog以及test/none目录下（详见readme）\n",
    "- 同时项目中提供了一个额外的[扩充数据](http://www.robots.ox.ac.uk/%7Evgg/data/pets/)\n",
    "- 数据解压后文件全部在images文件夹下，文件名的格式为{种类}_{序号}.jpg，比如 Abyssinian_1.jpg\n",
    "- 同时官方给出了所有图片的种类明细，比如Abyssinian是猫。所以应该把图片Abyssinian_1.jpg分类到train/cat的目录下面\n",
    "- 扩充数据集总共有7390张图片，猫的图片有2400张，狗的图片有4990张"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图片目录结构\n",
    "当前的图片目录结构如下\n",
    "```\n",
    "data\n",
    " ├── images [7390 images]\n",
    " ├── test\n",
    " │   └── none [12500 images]\n",
    " └── train\n",
    "     ├── cat [12500 images]\n",
    "     └── dog [12500 images]\n",
    "```\n",
    "我们需要把images下的7390张图片，根据官方给出的类别分类到train目录的cat和dog子目录中。分类成功的话新的数据集猫的图片数量应该为12500+2400=14900，狗的图片数量为12500+4990=17490。处理后的图片目录结构应该如下\n",
    "```\n",
    "data\n",
    " ├── test\n",
    " │   └── none [12500 images]\n",
    " └── train\n",
    "     ├── cat [14900 images]\n",
    "     └── dog [17490 images]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extral images:  7390\n",
      "Total cat images:  12500\n",
      "Total dog images:  12500\n",
      "After added extral images:\n",
      "Total cat images:  14900\n",
      "Total dog images:  17490\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "dog_breeds = ['american_bulldog', 'american_pit_bull_terrier','basset_hound','beagle','boxer',\n",
    "             'chihuahua','english_cocker_spaniel','english_setter','german_shorthaired','great_pyrenees',\n",
    "             'havanese','japanese_chin','keeshond','leonberger','miniature_pinscher','newfoundland','pomeranian',\n",
    "             'pug','saint_bernard','samoyed','scottish_terrier','shiba_inu','staffordshire_bull_terrier',\n",
    "             'wheaten_terrier','yorkshire_terrier']\n",
    "\n",
    "cat_breeds = ['Abyssinian','Bengal','Birman','Bombay','British_Shorthair','Egyptian_Mau','Maine_Coon','Persian',\n",
    "              'Ragdoll','Russian_Blue','Siamese','Sphynx']\n",
    "\n",
    "src = 'data/images/'\n",
    "dog_dest = 'data/train/dog/'\n",
    "cat_dest = 'data/train/cat/'\n",
    "\n",
    "def handle_extra_data(dest, breeds):\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        for name in files:\n",
    "            for val in breeds:\n",
    "                if(name.find(val)>-1):\n",
    "                    copyfile(src + name, dest + name)\n",
    "                    \n",
    "                    \n",
    "print(\"Total extral images: \", len([name for name in os.listdir(src) if os.path.isfile(os.path.join(src, name))]))\n",
    "print(\"Total cat images: \", len([name for name in os.listdir(cat_dest) if os.path.isfile(os.path.join(cat_dest, name))]))\n",
    "print(\"Total dog images: \", len([name for name in os.listdir(dog_dest) if os.path.isfile(os.path.join(dog_dest, name))]))\n",
    "\n",
    "handle_extra_data(dog_dest, dog_breeds)\n",
    "handle_extra_data(cat_dest, cat_breeds)\n",
    "\n",
    "\n",
    "print(\"After added extral images:\")\n",
    "print(\"Total cat images: \", len([name for name in os.listdir(cat_dest) if os.path.isfile(os.path.join(cat_dest, name))]))\n",
    "print(\"Total dog images: \", len([name for name in os.listdir(dog_dest) if os.path.isfile(os.path.join(dog_dest, name))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出深度特征\n",
    "- 根据当前训练以及测试集导出VGG16,VGG19,ResNet50,Xception以及InceptionV3的深度特征\n",
    "- VGG16,VGG19,ResNet50要求的图片的大小为（224， 224）\n",
    "- Xception，Inception要求的图片大小为（299，299）\n",
    "- 先对所有数据进行一个预处理的操作，把数据缩放到-1到1之间\n",
    "- 其次我们加入一个平局池化操作，一方面是缩小我们导出的深度特征文件的大小，另一方是防止过拟合\n",
    "- 最后使用Keras的ImageGenerator对数据进行增加处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tracy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "train_data_path = 'data/train/'\n",
    "test_data_path = 'data/test/'\n",
    "\n",
    "def save_bottleneck_features(MODEL, image_size, module_name, preprocess):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = Lambda(preprocess)(input_tensor)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_data_path, image_size, shuffle=False, batch_size=36)\n",
    "    test_generator = gen.flow_from_directory(test_data_path, image_size, shuffle=False, batch_size=36, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator)\n",
    "    test = model.predict_generator(test_generator)\n",
    "    with h5py.File(\"bottleneck_features/{}_bottleneck_features.h5\".format(module_name)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"{} extrac features total consumed: {} seconds\".format(module_name, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32390 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG16 extrac features total consumed: 258.84423875808716 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(VGG16, (224, 224), 'VGG16', vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32390 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG19 extrac features total consumed: 302.42244029045105 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(VGG19, (224, 224), 'VGG19', vgg19.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32390 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "ResNet50 extrac features total consumed: 253.90742802619934 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(ResNet50, (224, 224), 'ResNet50', resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32390 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "InceptionV3 extrac features total consumed: 344.6618912220001 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(InceptionV3, (299, 299), 'InceptionV3', inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32390 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Xception extrac features total consumed: 498.6959562301636 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(Xception, (299, 299), 'Xception', xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迁移学习\n",
    "- 至此针对以上模型的深度特征提取完毕\n",
    "- VGG16耗时约4分19秒，VGG19耗时越5分3秒，ResNet50耗时约4分14秒，InceptionV3耗时约5分45秒，Xception耗时约8分钟19秒\n",
    "- 依据这些深度特征我们可以来构建新的模型并且只需要构建最后一层\n",
    "- 这里首先构建一个dropout层，参数为0.5，最后构建一个全连接层来做分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7168,)\n",
      "Train on 25912 samples, validate on 6478 samples\n",
      "Epoch 1/10\n",
      "25912/25912 [==============================] - 5s 181us/step - loss: 0.1174 - acc: 0.9634 - val_loss: 0.0262 - val_acc: 0.9898\n",
      "Epoch 2/10\n",
      "25912/25912 [==============================] - 2s 92us/step - loss: 0.0297 - acc: 0.9904 - val_loss: 0.0142 - val_acc: 0.9954\n",
      "Epoch 3/10\n",
      "25912/25912 [==============================] - 2s 89us/step - loss: 0.0250 - acc: 0.9924 - val_loss: 0.0580 - val_acc: 0.9802\n",
      "Epoch 4/10\n",
      "25912/25912 [==============================] - 2s 86us/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0111 - val_acc: 0.9958\n",
      "Epoch 5/10\n",
      "25912/25912 [==============================] - 2s 67us/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0112 - val_acc: 0.9958\n",
      "Epoch 6/10\n",
      "25912/25912 [==============================] - 3s 104us/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0142 - val_acc: 0.9949\n",
      "Epoch 7/10\n",
      "25912/25912 [==============================] - 3s 106us/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0259 - val_acc: 0.9915\n",
      "Epoch 8/10\n",
      "25912/25912 [==============================] - 2s 73us/step - loss: 0.0124 - acc: 0.9959 - val_loss: 0.0115 - val_acc: 0.9961\n",
      "Epoch 9/10\n",
      "25912/25912 [==============================] - 2s 77us/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0282 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "25912/25912 [==============================] - 2s 71us/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0047 - val_acc: 0.9981\n",
      "Trainning model total consumed: 24.594088792800903 seconds\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import time\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "bottle_neck_files = [\"bottleneck_features/VGG16_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/VGG19_bottleneck_features.h5\", \n",
    "                    \"bottleneck_features/ResNet50_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/InceptionV3_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/Xception_bottleneck_features.h5\"]\n",
    "\n",
    "for filename in bottle_neck_files:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "print(X_train.shape[1:])\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "    \n",
    "print(\"Trainning model total consumed: {} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 0s 32us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "train_data_path = 'data/train/'\n",
    "test_data_path = 'data/test/'\n",
    "\n",
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_data_path, (224, 224), shuffle=False, batch_size=32, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('\\\\')+1:fname.rfind('.')])\n",
    "    df.at[index-1, 'label'] = y_pred[i]\n",
    "    \n",
    "\n",
    "df.to_csv('data/pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
