{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理\n",
    "- 原始数据集直接从Kaggle上下载，解压后train目录下一共有25000张图片，test目录下一共有12500张图片\n",
    "- 我们需要通过Keras ImageDataGenerator的flow_from_directory方法来加载我们的图片，所以我们需要将训练集和测试集的图片放到子文件夹中\n",
    "- 测试集很简单，建一个子目录，将文件全部移动过去就行\n",
    "- 训练集需要建立两个子目录，将狗和猫的图片分别移动到两个子目录中去\n",
    "- 训练集中的图片名称格式为{种类}.序号.jpg，比如 cat.1.jpg 或 dog.1.jpg。我们可以利用命名规则来移动训练集的图片\n",
    "\n",
    "当前的图片目录结构如下\n",
    "```\n",
    "data\n",
    " ├── test   [12500 images]\n",
    " └── train  [25000 images]\n",
    "```\n",
    "预处理后图片目录结构如下\n",
    "```\n",
    "data\n",
    " ├── test\n",
    " │   └── none [12500 images]\n",
    " └── train\n",
    "     ├── cat  [12500 images]\n",
    "     └── dog  [12500 images]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat images:  12500\n",
      "dog images:  12500\n",
      "test images:  12500\n"
     ]
    }
   ],
   "source": [
    "# 数据处理代码\n",
    "import os\n",
    "from shutil import move\n",
    "\n",
    "train_src = 'data/train/'\n",
    "test_src = 'data/test/'\n",
    "dog_dest = 'data/train/dog/'\n",
    "cat_dest = 'data/train/cat/'\n",
    "test_dest = 'data/test/none/'\n",
    "\n",
    "#创建子目录\n",
    "os.makedirs(dog_dest, exist_ok=True)\n",
    "os.makedirs(cat_dest, exist_ok=True)\n",
    "os.makedirs(test_dest, exist_ok=True)\n",
    "\n",
    "#移动测试图片至子文件夹中\n",
    "for root, dirs, files in os.walk(test_src):\n",
    "    if(root == test_src):\n",
    "        for name in files:\n",
    "            if(name.find('jpg')>-1):\n",
    "                move(test_src + name, test_dest + name)\n",
    "\n",
    "#移动训练集图片至对应的子文件夹中\n",
    "for root, dirs, files in os.walk(train_src):\n",
    "    if(root == train_src):\n",
    "        for name in files:\n",
    "            if(name.find('jpg')>-1 and name.find('cat')>-1):\n",
    "                move(train_src + name, cat_dest + name)\n",
    "            elif(name.find('jpg')>-1 and name.find('dog')>-1):\n",
    "                move(train_src + name, dog_dest + name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "print(\"cat images: \", \n",
    "      len([name for name in os.listdir(cat_dest) if os.path.isfile(os.path.join(cat_dest, name))]))\n",
    "print(\"dog images: \", \n",
    "      len([name for name in os.listdir(dog_dest) if os.path.isfile(os.path.join(dog_dest, name))]))\n",
    "print(\"test images: \", \n",
    "      len([name for name in os.listdir(test_dest) if os.path.isfile(os.path.join(test_dest, name))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出深度特征\n",
    "- 根据当前训练以及测试集导出VGG16,VGG19,ResNet50,Xception以及InceptionV3的深度特征\n",
    "- VGG16,VGG19,ResNet50要求的图片的大小为（224， 224）\n",
    "- Xception，Inception要求的图片大小为（299，299）\n",
    "- 先对所有数据进行一个预处理的操作，把数据缩放到-1到1之间\n",
    "- 其次我们加入一个平局池化操作，一方面是缩小我们导出的深度特征文件的大小，另一方是防止过拟合\n",
    "- 最后使用Keras的ImageGenerator导出深度特征的数组，存放在本地磁盘上供接下来的模型训练使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tracy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "train_data_path = 'data/train/'\n",
    "test_data_path = 'data/test/'\n",
    "\n",
    "def save_bottleneck_features(MODEL, image_size, module_name, preprocess):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = Lambda(preprocess)(input_tensor)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_data_path, image_size, shuffle=False)\n",
    "    test_generator = gen.flow_from_directory(test_data_path, image_size, shuffle=False, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator)\n",
    "    test = model.predict_generator(test_generator)\n",
    "    \n",
    "    with h5py.File(\"bottleneck_features/{}_bottleneck_features.h5\".format(module_name)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"{} extrac features total consumed: {} seconds\".format(module_name, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG16 extrac features total consumed: 205.36566758155823 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(VGG16, (224, 224), 'VGG16', vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG19 extrac features total consumed: 232.02474784851074 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(VGG19, (224, 224), 'VGG19', vgg19.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "ResNet50 extrac features total consumed: 210.49121832847595 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(ResNet50, (224, 224), 'ResNet50', resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "InceptionV3 extrac features total consumed: 274.9980471134186 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(InceptionV3, (299, 299), 'InceptionV3', inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Xception extrac features total consumed: 416.50056076049805 seconds\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(Xception, (299, 299), 'Xception', xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迁移学习\n",
    "- 至此针对以上模型的深度特征提取完毕\n",
    "- VGG16耗时约4分19秒，VGG19耗时越5分3秒，ResNet50耗时约4分14秒，InceptionV3耗时约5分45秒，Xception耗时约8分钟19秒\n",
    "- 依据这些深度特征我们可以来构建新的模型并且只需要构建最后一层\n",
    "- 这里首先构建一个dropout层，参数为0.5，最后构建一个全连接层来做分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import *\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def retrieve_features(files):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    \n",
    "    for filename in files:\n",
    "        with h5py.File(filename, 'r') as h:\n",
    "            X_train.append(np.array(h['train']))\n",
    "            X_test.append(np.array(h['test']))\n",
    "            y_train = np.array(h['label'])\n",
    "        \n",
    "    X_train = np.concatenate(X_train, axis=1)\n",
    "    X_test = np.concatenate(X_test, axis=1)\n",
    "    \n",
    "    return X_train, X_test, y_train\n",
    "\n",
    "    \n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    # construct model\n",
    "    input_tensor = Input(X_train.shape[1:])\n",
    "    x = BatchNormalization()(input_tensor)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # train model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, batch_size=200, epochs=10, validation_split=0.2, verbose=1)\n",
    "    end_time = time.time()\n",
    "    print(\"Trainning model total consumed:{} seconds\".format(end_time - start_time))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_submission_csv(X_test, model):\n",
    "\n",
    "    y_pred = model.predict(X_test, verbose=1)\n",
    "    y_pred = y_pred.clip(min=0.005, max=1)\n",
    "\n",
    "    df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    test_generator = gen.flow_from_directory('data/test/', (224, 224), shuffle=False, batch_size=32, class_mode=None)\n",
    "\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        index = int(fname[fname.rfind('\\\\')+1:fname.rfind('.')])\n",
    "        df.at[index-1, 'label'] = y_pred[i]\n",
    "\n",
    "    df.to_csv('data/pred.csv', index=None)\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.0430 - acc: 0.9838 - val_loss: 0.0169 - val_acc: 0.9940\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0200 - val_acc: 0.9930\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0329 - val_acc: 0.9900\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0282 - val_acc: 0.9920\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0173 - val_acc: 0.9948\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0239 - val_acc: 0.9934\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0375 - val_acc: 0.9892\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0301 - val_acc: 0.9922\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 8.8931e-04 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 0.9932\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 8.9801e-04 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9934\n",
      "Trainning model total consumed:14.610912322998047 seconds\n"
     ]
    }
   ],
   "source": [
    "# train using all the models bottleneck_features\n",
    "bottleneck_files = [\"bottleneck_features/VGG16_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/VGG19_bottleneck_features.h5\", \n",
    "                    \"bottleneck_features/ResNet50_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/InceptionV3_bottleneck_features.h5\",\n",
    "                    \"bottleneck_features/Xception_bottleneck_features.h5\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train = retrieve_features(bottleneck_files)\n",
    "\n",
    "model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 96us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "generate_submission_csv(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logloss(true_label, predicted):\n",
    "    if true_label == 1:\n",
    "        return -math.log(predicted)\n",
    "    else:\n",
    "        return -math.log(1 - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010005003335835344\n",
      "0.0010005003335835344\n",
      "48.35428695287496\n",
      "0.916290731874155\n"
     ]
    }
   ],
   "source": [
    "# 当我们预测正确时 true label = 1 , 我们预测的值为 0.999时\n",
    "print(logloss(1, 0.999))\n",
    "# 当我们预测正确时 true label = 0 , 我们预测的值为 0.001时\n",
    "print(logloss(0, 0.001))\n",
    "\n",
    "# 当我们预测错误时 true label = 1 , 我们预测的值为 0.4时\n",
    "print(logloss(1, 0.000000000000000000001))\n",
    "# 当我们预测错误时 true label = 0 , 我们预测的值为 0.6时\n",
    "print(logloss(0, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
