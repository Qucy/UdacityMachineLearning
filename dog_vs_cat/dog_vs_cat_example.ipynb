{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出深度特征\n",
    "- 首先我们导出VGG16,VGG19,ResNet50,Xception以及InceptionV3的深度特征\n",
    "- VGG16,VGG19,ResNet50要求的图片的大小为（224， 224）\n",
    "- Xception，Inception要求的图片大小为（299，299）\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG16 extrac features total consumed: 196.73024725914001 seconds\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "VGG19 extrac features total consumed: 228.9459409713745 seconds\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "ResNet50 extrac features total consumed: 211.36610960960388 seconds\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "InceptionV3 extrac features total consumed: 273.7162392139435 seconds\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Xception extrac features total consumed: 416.25546979904175 seconds\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "train_data_path = 'data/train/'\n",
    "test_data_path = 'data/test/'\n",
    "\n",
    "def save_bottleneck_features(MODEL, image_size, module_name, preprocess):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = Lambda(preprocess)(input_tensor)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(train_data_path, image_size, shuffle=False, batch_size=32)\n",
    "    test_generator = gen.flow_from_directory(test_data_path, image_size, shuffle=False, batch_size=32, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator)\n",
    "    test = model.predict_generator(test_generator)\n",
    "    with h5py.File(\"bottleneck_features/{}_bottleneck_features.h5\".format(module_name)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"{} extrac features total consumed: {} seconds\".format(module_name, end_time - start_time))\n",
    "    \n",
    "\n",
    "save_bottleneck_features(VGG16, (224, 224), 'VGG16', vgg16.preprocess_input)\n",
    "save_bottleneck_features(VGG19, (224, 224), 'VGG19', vgg19.preprocess_input)\n",
    "save_bottleneck_features(ResNet50, (224, 224), 'ResNet50', resnet50.preprocess_input)\n",
    "save_bottleneck_features(InceptionV3, (299, 299), 'InceptionV3', inception_v3.preprocess_input)\n",
    "save_bottleneck_features(Xception, (299, 299), 'Xception', xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.9648 - acc: 0.8284 - val_loss: 0.1438 - val_acc: 0.9592\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 1s 57us/step - loss: 0.2431 - acc: 0.9405 - val_loss: 0.0879 - val_acc: 0.9728\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.1697 - acc: 0.9574 - val_loss: 0.2004 - val_acc: 0.9432\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.1369 - acc: 0.9629 - val_loss: 0.0807 - val_acc: 0.9722\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.1209 - acc: 0.9652 - val_loss: 0.0598 - val_acc: 0.9774\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.1087 - acc: 0.9677 - val_loss: 0.1349 - val_acc: 0.9550\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.1008 - acc: 0.9666 - val_loss: 0.1056 - val_acc: 0.9600\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.0975 - acc: 0.9671 - val_loss: 0.1951 - val_acc: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2267a6e82e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "#for filename in [\"bottleneck_features/gap_ResNet50.h5\", \"bottleneck_features/gap_Xception.h5\", \"bottleneck_features/gap_InceptionV3.h5\"]:\n",
    "for filename in [\"bottleneck_features/VGG16_bottleneck_features.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "print(X_train.shape[1:])\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 0s 21us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tracy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_data_path, (224, 224), shuffle=False, batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('\\\\')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('data/pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "123 extrac features total consumed: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "duration = start_time - end_time\n",
    "\n",
    "print(float(duration))\n",
    "\n",
    "print(\"{} extrac features total consumed: {} seconds\".format('123', duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
